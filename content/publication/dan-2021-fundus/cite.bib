@article{DAN2021370,
title = {Fusion of multi-source retinal fundus images via automatic registration for clinical diagnosis},
journal = {Neurocomputing},
volume = {459},
pages = {370-382},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.05.091},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221008547},
author = {Tingting Dan and Yu Hu and Chu Han and Zhihao Fan and Zhuobin Huang and Bin Zhang and Guihua Tao and Baoyi Liu and Honghua Yu and Hongmin Cai},
keywords = {Retinal fundus image registration, Multiple sources, Adjustable threshold selection, Multiple features, Geometric structure constraint},
abstract = {Diabetic retinopathy, age-related macular degeneration and glaucoma, are the leading causes of visual impairment or blindness of the population across different ages. Retinal fundus imaging is a clinically regular tool for the diagnosis of retinal diseases. In the interest of having a comprehensive understanding of the fundus condition, it is valuable to leverage multiple fundus images from different modalities. However, a direct fusion of the multi-source fundus images eases to mis-align the physiological structure or spatial position due to possible eyeball rotations or head movements. The problem turns out to be more severe if the images were corrupted by ill conditions on eyes, such as micro-bleeding and plaques. To tackle this problem, we propose a multi-source registration model for retinal fundus images. Our proposed method considers multiple correspondences and dual structural constraints during the registration process. The method firstly selects adequate feature points by an adjustable threshold selection strategy. Then a feature-guided correspondence estimation model is established to build complementary features. Finally, their spatial transformation is built by using mean shift evolution. The evolution is guided by Tikhonov regularization on dual geometric structures. It overcomes the mess of mean shift vector field and mitigating the ill-posed displacement in field recovery. We have conducted our method on the collected 220 multi-source retinal fundus image pairs, which involve minor and larger displacement or severe retinopathy lesions, as well as additive different intensities of Gaussian noises. Extensive experiments demonstrate that the proposed method consistently outperforms seven feature-based methods.}
}